{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataProcessing and generation of TfRecords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow for TfRecords, neural network architecture and training\n",
    "import tensorflow as tf\n",
    "\n",
    "#Librosa for parsing audio files into numpy and audio processing tools\n",
    "import librosa\n",
    "\n",
    "#Pandas for DataFrame handling\n",
    "import pandas as pd\n",
    "\n",
    "#other useful libraries\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import glob\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "import zipfile\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "tf.random.set_seed(999)\n",
    "np.random.seed(999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filenames and paths of Clean audio are found and split into Train:Validation:Test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the paths for Clean and noise audio files\n",
    "mozilla_basepath = 'en'\n",
    "urbansound_basepath = 'UrbanSound8K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f1f6414c04e74453065e1b7fc1639c6f728dc03ed95890...</td>\n",
       "      <td>common_voice_en_20009651.mp3</td>\n",
       "      <td>It just didn't seem fair.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f1f6414c04e74453065e1b7fc1639c6f728dc03ed95890...</td>\n",
       "      <td>common_voice_en_20009653.mp3</td>\n",
       "      <td>The anticipated synergies of the two modes of ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1f6414c04e74453065e1b7fc1639c6f728dc03ed95890...</td>\n",
       "      <td>common_voice_en_20009655.mp3</td>\n",
       "      <td>The fossil fuels include coal, petroleum and n...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1f6414c04e74453065e1b7fc1639c6f728dc03ed95890...</td>\n",
       "      <td>common_voice_en_20009654.mp3</td>\n",
       "      <td>Eventually, they named the complex after him.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f208e11e4b036d4728602fef34b9f1158faa601f20c63a...</td>\n",
       "      <td>common_voice_en_19684651.mp3</td>\n",
       "      <td>He was the grandfather of Arent S. Crowninshield.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  f1f6414c04e74453065e1b7fc1639c6f728dc03ed95890...   \n",
       "1  f1f6414c04e74453065e1b7fc1639c6f728dc03ed95890...   \n",
       "2  f1f6414c04e74453065e1b7fc1639c6f728dc03ed95890...   \n",
       "3  f1f6414c04e74453065e1b7fc1639c6f728dc03ed95890...   \n",
       "4  f208e11e4b036d4728602fef34b9f1158faa601f20c63a...   \n",
       "\n",
       "                           path  \\\n",
       "0  common_voice_en_20009651.mp3   \n",
       "1  common_voice_en_20009653.mp3   \n",
       "2  common_voice_en_20009655.mp3   \n",
       "3  common_voice_en_20009654.mp3   \n",
       "4  common_voice_en_19684651.mp3   \n",
       "\n",
       "                                            sentence  up_votes  down_votes  \\\n",
       "0                          It just didn't seem fair.         2           1   \n",
       "1  The anticipated synergies of the two modes of ...         2           0   \n",
       "2  The fossil fuels include coal, petroleum and n...         3           1   \n",
       "3      Eventually, they named the complex after him.         2           0   \n",
       "4  He was the grandfather of Arent S. Crowninshield.         2           0   \n",
       "\n",
       "   age gender accent locale  segment  \n",
       "0  NaN    NaN    NaN     en      NaN  \n",
       "1  NaN    NaN    NaN     en      NaN  \n",
       "2  NaN    NaN    NaN     en      NaN  \n",
       "3  NaN    NaN    NaN     en      NaN  \n",
       "4  NaN    NaN    NaN     en      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe of clean audio(Mozilla Common voice dataset)\n",
    "mozilla_data = pd.read_csv(mozilla_basepath + '/train.tsv', sep = '\\t')\n",
    "mozilla_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files:  435947\n"
     ]
    }
   ],
   "source": [
    "clean_files = mozilla_data['path'].values\n",
    "\n",
    "#Randomly shuffle all the file names\n",
    "np.random.shuffle(clean_files)\n",
    "\n",
    "print(\"Number of files: \", len(clean_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment in case of some missing files after download and extraction of the dataset.\n",
    "\n",
    "#files_present = os.listdir('en/clips')\n",
    "#print(files_present[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#clean_paths = []\n",
    "#c = 0\n",
    "#for a in clean_files:\n",
    "#    if a in files_present:\n",
    "#        clean_paths.append(os.path.join(mozilla_basepath, 'clips', a))\n",
    "#    c += 1\n",
    "#    if c%2000==0:\n",
    "#        print(c)\n",
    "#import gc\n",
    "#files_present = []\n",
    "#gc.collect()\n",
    "#files = pd.DataFrame(clean_paths)\n",
    "#files.to_csv(\"cleanpaths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Files present in the folder are cross-checked and a csv file was saved.\n",
    "\n",
    "files = pd.read_csv('cleanpaths.csv')\n",
    "clean_paths = files['0'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 1000 files as Validation sets and remaianing as training examples\n",
    "\n",
    "clean_val_paths = clean_paths[:1000]\n",
    "clean_train_paths = clean_paths[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUmber of training files:  427053\n",
      "Number of validation files:  1000\n"
     ]
    }
   ],
   "source": [
    "print(\"NUmber of training files: \", len(clean_train_paths))\n",
    "print(\"Number of validation files: \", len(clean_val_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### As there are 4,27,000 files, We have truncated the number to 1,00,000 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_train_paths = clean_train_paths[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similarly the same is done for testsets of clean audio files.\n",
    "\n",
    "clean_test_files = pd.read_csv(mozilla_basepath + '/test.tsv', sep = '\\t')\n",
    "clean_test_files = clean_test_files['path'].values\n",
    "clean_test_paths = [os.path.join(mozilla_basepath, 'clips', a) for a in clean_test_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing files 16029\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of testing files\", len(clean_test_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File names and paths of noise audio are also extracted from metadata files provided along with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data from metadata files\n",
    "urbansound_metadata = pd.read_csv(os.path.join(urbansound_basepath, 'metadata', 'UrbanSound8K.csv'))\n",
    "urbansound_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     990\n",
       "5     936\n",
       "3     925\n",
       "2     888\n",
       "1     873\n",
       "7     838\n",
       "10    837\n",
       "6     823\n",
       "9     816\n",
       "8     806\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the files in the noises dataset are split into 10 folds\n",
    "# We are going to use 9folds for training,val and 10th fold as test\n",
    "urbansound_metadata['fold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8727</th>\n",
       "      <td>99812-1-2-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>159.522205</td>\n",
       "      <td>163.522205</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>99812-1-3-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>181.142431</td>\n",
       "      <td>183.284976</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>99812-1-4-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>242.691902</td>\n",
       "      <td>246.197885</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>99812-1-5-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>253.209850</td>\n",
       "      <td>255.741948</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>99812-1-6-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>332.289233</td>\n",
       "      <td>334.821332</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7895 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         slice_file_name    fsID       start         end  salience  fold  \\\n",
       "0       100032-3-0-0.wav  100032    0.000000    0.317551         1     5   \n",
       "1     100263-2-0-117.wav  100263   58.500000   62.500000         1     5   \n",
       "2     100263-2-0-121.wav  100263   60.500000   64.500000         1     5   \n",
       "3     100263-2-0-126.wav  100263   63.000000   67.000000         1     5   \n",
       "4     100263-2-0-137.wav  100263   68.500000   72.500000         1     5   \n",
       "...                  ...     ...         ...         ...       ...   ...   \n",
       "8727     99812-1-2-0.wav   99812  159.522205  163.522205         2     7   \n",
       "8728     99812-1-3-0.wav   99812  181.142431  183.284976         2     7   \n",
       "8729     99812-1-4-0.wav   99812  242.691902  246.197885         2     7   \n",
       "8730     99812-1-5-0.wav   99812  253.209850  255.741948         2     7   \n",
       "8731     99812-1-6-0.wav   99812  332.289233  334.821332         2     7   \n",
       "\n",
       "      classID             class  \n",
       "0           3          dog_bark  \n",
       "1           2  children_playing  \n",
       "2           2  children_playing  \n",
       "3           2  children_playing  \n",
       "4           2  children_playing  \n",
       "...       ...               ...  \n",
       "8727        1          car_horn  \n",
       "8728        1          car_horn  \n",
       "8729        1          car_horn  \n",
       "8730        1          car_horn  \n",
       "8731        1          car_horn  \n",
       "\n",
       "[7895 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All files other than 10th fold are collected\n",
    "\n",
    "urbansound_train = urbansound_metadata[urbansound_metadata['fold']!= 10]\n",
    "urbansound_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classses present:  10\n"
     ]
    }
   ],
   "source": [
    "# The audio files are collected from 10 sources as mentioned in the dataset website\n",
    "\n",
    "class_ids = np.unique(urbansound_metadata['classID'].values)\n",
    "print(\"Number of classses present: \", len(class_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class ID  0  has 900  files\n",
      "Class ID  1  has 396  files\n",
      "Class ID  2  has 900  files\n",
      "Class ID  3  has 900  files\n",
      "Class ID  4  has 900  files\n",
      "Class ID  5  has 907  files\n",
      "Class ID  6  has 342  files\n",
      "Class ID  7  has 904  files\n",
      "Class ID  8  has 846  files\n",
      "Class ID  9  has 900  files\n"
     ]
    }
   ],
   "source": [
    "# Checking if all the noises have equal share among the whole dataset on an average.\n",
    "\n",
    "all_files = []\n",
    "for a in class_ids:\n",
    "    per_class_files = urbansound_train[urbansound_train['classID']==a][['slice_file_name', 'fold']].values\n",
    "    per_class_files = [os.path.join(urbansound_basepath, 'audio', 'fold'+str(a[1]), a[0]) for a in per_class_files]\n",
    "    print(\"Class ID \",a,\" has\", len(per_class_files), \" files\")\n",
    "    all_files.extend(per_class_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UrbanSound8K\\\\audio\\\\fold5\\\\100852-0-0-0.wav',\n",
       " 'UrbanSound8K\\\\audio\\\\fold5\\\\100852-0-0-1.wav',\n",
       " 'UrbanSound8K\\\\audio\\\\fold5\\\\100852-0-0-10.wav',\n",
       " 'UrbanSound8K\\\\audio\\\\fold5\\\\100852-0-0-11.wav',\n",
       " 'UrbanSound8K\\\\audio\\\\fold5\\\\100852-0-0-12.wav']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Noise number of files:  7695\n",
      "Validation Noise number of files:  200\n"
     ]
    }
   ],
   "source": [
    "# Randomly shuffle the list elements\n",
    "\n",
    "np.random.shuffle(all_files)\n",
    "#200 noise files are split for \n",
    "\n",
    "ub_val_paths = all_files[:200]\n",
    "ub_train_paths = all_files[200:]\n",
    "print(\"Training Noise number of files: \", len(ub_train_paths))\n",
    "print(\"Validation Noise number of files: \", len(ub_val_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UrbanSound8K\\\\audio\\\\fold10\\\\119067-0-0-0.wav',\n",
       " 'UrbanSound8K\\\\audio\\\\fold10\\\\119067-0-0-1.wav',\n",
       " 'UrbanSound8K\\\\audio\\\\fold10\\\\119067-0-0-2.wav',\n",
       " 'UrbanSound8K\\\\audio\\\\fold10\\\\167464-0-0-0.wav',\n",
       " 'UrbanSound8K\\\\audio\\\\fold10\\\\167464-0-0-1.wav']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the 10th fold examples from the dataset as test set\n",
    "\n",
    "ub_test_data = urbansound_metadata[urbansound_metadata['fold']==10]\n",
    "all_files = []\n",
    "for a in class_ids:\n",
    "    per_class_files = ub_test_data[ub_test_data['classID']==a][['slice_file_name', 'fold']].values\n",
    "    per_class_files = [os.path.join(urbansound_basepath, 'audio', 'fold'+str(a[1]),a[0]) for a in per_class_files]\n",
    "    all_files.extend(per_class_files)\n",
    "all_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing noise number of files:  837\n"
     ]
    }
   ],
   "source": [
    "ub_test_paths = all_files\n",
    "print(\"Testing noise number of files: \", len(ub_test_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next is the data processing phase, now that we have finished collecting paths for files  under Train, Validation and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important parameters\n",
    "\n",
    "window_length = 256\n",
    "overlap = round(0.25*window_length)\n",
    "fs = 16000\n",
    "max_duration = 0.8\n",
    "window = scipy.signal.hamming(window_length, sym = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function takes in input paths for the clean audio file and noise file and does the following to finally create one exmaple\n",
    "#We give the clean audio file name and a list of noise files, one noise is randomly picked and added to the clean audio.\n",
    "\n",
    "#1. Removes silent frames from both noise and clean audio.\n",
    "#2. Getting the both audio clips to the same length<=maximum duration(fixed by us)\n",
    "#3. Based on a formula for addition of singal and noise so that the SNR(signal to noise ratio) is not unreal, the signals \n",
    "# are added.\n",
    "\n",
    "def process(file, noise_files):\n",
    "\n",
    "    #Important parameters\n",
    "    window_length = 256\n",
    "    overlap = round(0.25*window_length)\n",
    "    fs = 16000\n",
    "    max_duration = 0.8\n",
    "    window = scipy.signal.hamming(window_length, sym = False)\n",
    "    \n",
    "    #Load Audio file\n",
    "    audio, sr = librosa.load(file,sr=fs)\n",
    "    audio = librosa.util.normalize(audio)\n",
    "    \n",
    "    #Removing silent frames from the audio loaded\n",
    "    trimmed = []\n",
    "    indices = librosa.effects.split(audio, hop_length = overlap, top_db = 20)\n",
    "    for index in indices:\n",
    "        trimmed.extend(audio[index[0]: index[1]])\n",
    "    clean_audio = trimmed\n",
    "    \n",
    "    #Adding randomly picked Noise\n",
    "    noise_filename = np.random.choice(noise_files)\n",
    "    noise_audio, sr = librosa.load(noise_filename, fs)\n",
    "    \n",
    "    \n",
    "    #Removing silent frames from Noise\n",
    "    noise_trimmed = []\n",
    "    indices = librosa.effects.split(noise_audio, hop_length = overlap, top_db = 20)\n",
    "    for i in indices:\n",
    "        noise_trimmed.extend(noise_audio[i[0]:i[1]])\n",
    "    noise_audio = noise_trimmed\n",
    "    \n",
    "    #Sampling random fixed length snippets from the audio\n",
    "    audio_duration_secs = librosa.core.get_duration(clean_audio, fs)\n",
    "    if audio_duration_secs > max_duration:\n",
    "        audio_duration_ms = math.floor(audio_duration_secs*fs)\n",
    "        duration_ms = math.floor(max_duration*fs)\n",
    "        idx = np.random.randint(0 , audio_duration_ms - duration_ms)\n",
    "        clean_audio = clean_audio[idx: idx + duration_ms]\n",
    "    \n",
    "    #Adding noise to noise to make it atleast as long as the input clean audio\n",
    "    if len(clean_audio)>=len(noise_audio):\n",
    "        while len(clean_audio)>=len(noise_audio):\n",
    "            noise_audio = np.append(noise_audio, noise_audio)\n",
    "    clean_audio = np.array(clean_audio)\n",
    "    noise_audio = np.array(noise_audio)\n",
    "    \n",
    "    #Picking up a random segment from the noise \n",
    "    ind = np.random.randint(0, noise_audio.size - clean_audio.size)\n",
    "    noiseSegment = noise_audio[ind : ind + clean_audio.size]\n",
    "    \n",
    "    #Mixing the two signals\n",
    "    clean_power = np.sum((clean_audio**2))\n",
    "    noise_power = np.sum(noiseSegment ** 2)\n",
    "    noisyAudio = clean_audio + np.sqrt(clean_power / noise_power)*noiseSegment\n",
    "\n",
    "    #Extracting STFT features from noisy audio\n",
    "    noisy_spectrogram = librosa.stft(noisyAudio, n_fft=window_length, win_length=window_length, hop_length=overlap,\n",
    "                            window=window, center=True)\n",
    "    noise_phase = np.angle(noisy_spectrogram)\n",
    "    noise_magnitude = np.abs(noisy_spectrogram)\n",
    "    \n",
    "    #Extracting featues from Clean audio\n",
    "    clean_spectrogram = librosa.stft(clean_audio, n_fft=window_length, win_length=window_length, hop_length=overlap,\n",
    "                            window=window, center=True)\n",
    "    clean_phase = np.angle(clean_spectrogram)\n",
    "    clean_magnitude = np.abs(clean_spectrogram)\n",
    "    \n",
    "    #Standard Scaler is used for normalisation\n",
    "    scaler = StandardScaler(copy=False, with_mean=True, with_std=True)\n",
    "    noise_magnitude = scaler.fit_transform(noise_magnitude)\n",
    "    clean_magnitude = scaler.transform(clean_magnitude)\n",
    "    \n",
    "    return noise_magnitude, clean_magnitude, noise_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper funtions for creating tf_records as mentioned in tensorflow tfrecords documentation\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def get_tf_feature(noise_stft_mag_features, clean_stft_magnitude, noise_stft_phase):\n",
    "    noise_stft_mag_features = noise_stft_mag_features.astype(np.float32).tostring()\n",
    "    clean_stft_magnitude = clean_stft_magnitude.astype(np.float32).tostring()\n",
    "    noise_stft_phase = noise_stft_phase.astype(np.float32).tostring()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'noise_stft_phase': _bytes_feature(noise_stft_phase),\n",
    "        'noise_stft_mag_features': _bytes_feature(noise_stft_mag_features),\n",
    "        'clean_stft_magnitude': _bytes_feature(clean_stft_magnitude)}))\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "#Create tfrecords combining Noise and clean audio, both for validation and train data\n",
    "\n",
    "def tf_record(clean_files, noise_files, size, type_):\n",
    "    \n",
    "    #Important parameters\n",
    "    window_length = 256\n",
    "    overlap = round(0.25*window_length)\n",
    "    fs = 16000\n",
    "    max_duration = 0.8\n",
    "    window = scipy.signal.hamming(window_length, sym = False)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for i in range(0, len(clean_files), size):\n",
    "        \n",
    "        tfrecord_filename = 'records/' + type_ + str(count) + '.tfrecords'\n",
    "    \n",
    "        if os.path.isfile(tfrecord_filename):\n",
    "            print(f\"Skipping {tfrecord_filename}\")\n",
    "            count += 1\n",
    "            continue\n",
    "\n",
    "        writer = tf.io.TFRecordWriter(tfrecord_filename)\n",
    "        clean_files_sub = clean_files[i:i+size]\n",
    "        print(f\"{type_} Processing files from: {i} to {i+size}\")\n",
    "        \n",
    "        out = []\n",
    "        for file in clean_files_sub:\n",
    "            out.append(process(file, noise_files))\n",
    "        gc.collect()\n",
    "        \n",
    "        #Based on output from previos function defined above, tfrecord contents are generated.\n",
    "        for o in out:\n",
    "            noise_stft_magnitude = o[0]\n",
    "            clean_stft_magnitude = o[1]\n",
    "            noise_stft_phase = o[2]\n",
    "            \n",
    "            numFeatures = 129 \n",
    "            numSegments = 8\n",
    "            \n",
    "            noisySTFT = np.concatenate([noise_stft_magnitude[:, 0:numSegments-1], noise_stft_magnitude],axis=1)\n",
    "            stftsegments = np.zeros((numFeatures,numSegments,noisySTFT.shape[-1]-numSegments+1))\n",
    "            for index in range(noisySTFT.shape[1]-numSegments+1):\n",
    "                stftsegments[:,:,index] = noisySTFT[:,index:index+numSegments]\n",
    "            noise_stft_mag_features = np.transpose(stftsegments, (2,0,1))\n",
    "            \n",
    "            clean_stft_magnitude = np.transpose(clean_stft_magnitude,(1,0))\n",
    "            noise_stft_phase = np.transpose(noise_stft_phase, (1,0))\n",
    "            noise_stft_mag_features = np.expand_dims(noise_stft_mag_features, axis=3)\n",
    "            clean_stft_magnitude = np.expand_dims(clean_stft_magnitude, axis=2)\n",
    "            \n",
    "            for x,y,p in zip(noise_stft_mag_features, clean_stft_magnitude, noise_stft_phase):\n",
    "                y = np.expand_dims(y, 2)\n",
    "                example = get_tf_feature(x, y, p)\n",
    "                writer.write(example.SerializeToString())\n",
    "        count += 1\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping records/val0.tfrecords\n",
      "Skipping records/train0.tfrecords\n",
      "Skipping records/train1.tfrecords\n",
      "Skipping records/train2.tfrecords\n",
      "Skipping records/train3.tfrecords\n",
      "Skipping records/train4.tfrecords\n",
      "Skipping records/train5.tfrecords\n",
      "Skipping records/train6.tfrecords\n",
      "Skipping records/train7.tfrecords\n",
      "Skipping records/train8.tfrecords\n",
      "Skipping records/train9.tfrecords\n",
      "Skipping records/train10.tfrecords\n",
      "Skipping records/train11.tfrecords\n",
      "Skipping records/train12.tfrecords\n",
      "train Processing files from: 130000 to 140000\n",
      "train Processing files from: 140000 to 150000\n",
      "train Processing files from: 150000 to 160000\n",
      "train Processing files from: 160000 to 170000\n",
      "train Processing files from: 170000 to 180000\n",
      "train Processing files from: 180000 to 190000\n",
      "train Processing files from: 190000 to 200000\n",
      "train Processing files from: 200000 to 210000\n",
      "train Processing files from: 210000 to 220000\n"
     ]
    }
   ],
   "source": [
    "# Functions are called to create respective tfrecord files\n",
    "\n",
    "tf_record(clean_val_paths,ub_val_paths, 2000, \"val\")\n",
    "tf_record(clean_train_paths,ub_train_paths,10000,\"train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
